"""
DiagAgent Gradio Web Interface
åŸºäº README ä¸­çš„ ğŸ¤–DiagAgent éƒ¨åˆ†è‡ªåŠ¨ç”Ÿæˆçš„å¯è¿è¡Œå‰ç«¯ç•Œé¢

åŠŸèƒ½è¯´æ˜:
- æ”¯æŒå¤šè½®äº¤äº’å¼è¯Šæ–­
- è¾“å…¥æ‚£è€…ä¿¡æ¯(å¹´é¾„ã€æ€§åˆ«ã€ä¸»è¯‰ã€ç—…å²ç­‰)
- æ™ºèƒ½æ¨èæ£€æŸ¥é¡¹ç›®æˆ–ç»™å‡ºæœ€ç»ˆè¯Šæ–­
- å¯æŸ¥çœ‹å®Œæ•´å¯¹è¯å†å²
"""

import gradio as gr
from typing import List, Dict, Tuple
import os

# ============================================================================
# ç³»ç»Ÿæç¤ºè¯ (æ¥è‡ª README ç¤ºä¾‹)
# ============================================================================
DIAGNOSE_INSTRUCTION = """You are a medical AI assistant. Help the doctor with diagnosis by analyzing patient information, suggesting relevant tests, and providing a final diagnosis when sufficient information is available.

RESPONSE FORMAT:

If more information is needed:
```
Current diagnosis: [your diagnosis according to the information provided]
Based on the patient's initial presentation, the following investigation(s) should be performed: [one additional test]
Reason: [reason for the test]
```

If sufficient information exists for diagnosis:
```
The available information is sufficient to make a diagnosis.

Diagnosis: [Diagnosis result]
Reason: [Diagnosis reason]
```"""


# ============================================================================
# DiagAgent æ¨¡å‹ç±» (åŸºäº README ä¸­çš„ç¤ºä¾‹ä»£ç )
# ============================================================================
class TransformersLocalDiagAgent:
    """
    åŸºäº Transformers åº“çš„æœ¬åœ° DiagAgent æ¨¡å‹
    æ³¨æ„: éœ€è¦å…ˆä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°æˆ–ä» HuggingFace åŠ è½½
    """
    def __init__(self, model_name_or_path: str = "Henrychur/DiagAgent-14B",
                 max_tokens: int = 8192, temperature: float = 0.0) -> None:
        """
        åˆå§‹åŒ– DiagAgent æ¨¡å‹

        Args:
            model_name_or_path: æ¨¡å‹è·¯å¾„æˆ– HuggingFace æ¨¡å‹åç§°
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: é‡‡æ ·æ¸©åº¦ (0.0 ä¸ºè´ªå©ªè§£ç )
        """
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM

            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name_or_path}...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name_or_path,
                trust_remote_code=True
            )
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name_or_path,
                trust_remote_code=True,
                torch_dtype="auto",
                device_map="auto",
                # å¦‚æœæ²¡æœ‰å®‰è£… flash_attention_2,å¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
                # attn_implementation="flash_attention_2"
            )
            self.max_tokens = max_tokens
            self.temperature = temperature
            self.device = self.model.device
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ! è®¾å¤‡: {self.device}")

        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ...")
            self.model = None
            self.tokenizer = None

    def diagnose(self, messages: List[Dict[str, str]]) -> str:
        """
        æ‰§è¡Œå¤šè½®è¯Šæ–­

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨,æ ¼å¼ä¸º [{"role": "system/user/assistant", "content": "..."}]

        Returns:
            ç”Ÿæˆçš„è¯Šæ–­å“åº”
        """
        # å¦‚æœæ¨¡å‹æœªåŠ è½½æˆåŠŸ,è¿”å›æ¨¡æ‹Ÿå“åº”
        if self.model is None or self.tokenizer is None:
            return self._mock_diagnose(messages)

        try:
            # åº”ç”¨èŠå¤©æ¨¡æ¿
            text = self.tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
            model_inputs = self.tokenizer([text], return_tensors="pt").to(self.device)

            # ç”Ÿæˆå“åº”
            generated_ids = self.model.generate(
                **model_inputs,
                max_new_tokens=self.max_tokens,
                temperature=self.temperature,
                do_sample=(self.temperature > 0),
                eos_token_id=self.tokenizer.eos_token_id
            )

            # ç§»é™¤æç¤ºè¯éƒ¨åˆ†
            generated_ids = [
                output_ids[len(input_ids):]
                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
            return response.strip().replace("```", "")

        except Exception as e:
            return f"è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {str(e)}"

    def _mock_diagnose(self, messages: List[Dict[str, str]]) -> str:
        """
        æ¨¡æ‹Ÿè¯Šæ–­å“åº” (å½“æ¨¡å‹æœªåŠ è½½æ—¶ä½¿ç”¨)
        """
        user_content = messages[-1]["content"] if messages else ""

        # ç®€å•çš„æ¨¡æ‹Ÿé€»è¾‘
        if "æ£€æŸ¥ç»“æœ" in user_content or "exam result" in user_content.lower():
            return """The available information is sufficient to make a diagnosis.

Diagnosis: æ ¹æ®æ‚£è€…çš„ç—‡çŠ¶ã€ç—…å²å’Œæ£€æŸ¥ç»“æœ,åˆæ­¥è¯Šæ–­ä¸ºç›¸å…³ç–¾ç—…ã€‚
Reason: ç»¼åˆæ‚£è€…çš„ä¸´åºŠè¡¨ç°ã€æ—¢å¾€ç—…å²ä»¥åŠæ£€æŸ¥ç»“æœ,ç¬¦åˆè¯¥è¯Šæ–­çš„å…¸å‹ç‰¹å¾ã€‚å»ºè®®è¿›ä¸€æ­¥è§‚å¯Ÿå’Œæ²»ç–—ã€‚

(æ³¨æ„: è¿™æ˜¯æ¨¡æ‹Ÿå“åº”,å®é™…ä½¿ç”¨æ—¶è¯·åŠ è½½çœŸå®æ¨¡å‹)"""
        else:
            return """Current diagnosis: åŸºäºç°æœ‰ä¿¡æ¯çš„åˆæ­¥è¯Šæ–­å‡è®¾
Based on the patient's initial presentation, the following investigation(s) should be performed: è¡€å¸¸è§„æ£€æŸ¥ (Complete Blood Count)
Reason: éœ€è¦è¯„ä¼°æ‚£è€…çš„åŸºç¡€è¡€æ¶²çŠ¶å†µ,æ’é™¤æ„ŸæŸ“ã€è´«è¡€ç­‰å¯èƒ½æ€§ã€‚

(æ³¨æ„: è¿™æ˜¯æ¨¡æ‹Ÿå“åº”,å®é™…ä½¿ç”¨æ—¶è¯·åŠ è½½çœŸå®æ¨¡å‹)"""


# ============================================================================
# å…¨å±€å˜é‡
# ============================================================================
# åˆå§‹åŒ–æ¨¡å‹ (å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–ç•Œé¢é€‰æ‹©æ¨¡å‹)
MODEL_NAME = os.getenv("DIAGAGENT_MODEL", "Henrychur/DiagAgent-14B")
diagagent = None  # å»¶è¿ŸåŠ è½½


# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ============================================================================
def initialize_model(model_choice: str, use_mock: bool = False) -> str:
    """åˆå§‹åŒ–æˆ–åˆ‡æ¢æ¨¡å‹"""
    global diagagent

    if use_mock:
        diagagent = TransformersLocalDiagAgent(model_choice)
        diagagent.model = None  # å¼ºåˆ¶ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        return "âœ… ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ (æœªåŠ è½½çœŸå®æ¨¡å‹)"

    try:
        diagagent = TransformersLocalDiagAgent(model_choice)
        if diagagent.model is not None:
            return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_choice}"
        else:
            return "âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥,å·²åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"


def format_patient_info(age: str, gender: str, chief_complaint: str,
                       history_present: str, past_medical: str,
                       family_history: str, allergy_history: str,
                       personal_history: str) -> str:
    """
    æ ¼å¼åŒ–æ‚£è€…ä¿¡æ¯ä¸ºæ ‡å‡†è¾“å…¥æ ¼å¼
    """
    info_parts = []

    if age and gender:
        info_parts.append(f"- Patient Information: {age} y/o {gender}")

    if chief_complaint:
        info_parts.append(f"- Chief Complaint: {chief_complaint}")

    if history_present:
        info_parts.append(f"- History of Present Illness: {history_present}")

    if past_medical:
        info_parts.append(f"- Past Medical History: {past_medical}")

    if personal_history:
        info_parts.append(f"- Personal History: {personal_history}")

    if family_history:
        info_parts.append(f"- Family History: {family_history}")

    if allergy_history:
        info_parts.append(f"- Allergy History: {allergy_history}")

    return "\n".join(info_parts)


def start_diagnosis(age: str, gender: str, chief_complaint: str,
                   history_present: str, past_medical: str,
                   family_history: str, allergy_history: str,
                   personal_history: str) -> Tuple[List, str, List]:
    """
    å¼€å§‹æ–°çš„è¯Šæ–­ä¼šè¯

    Returns:
        (chat_history, diagnosis_result, message_history)
    """
    global diagagent

    # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
    if diagagent is None:
        diagagent = TransformersLocalDiagAgent(MODEL_NAME)

    # æ ¼å¼åŒ–æ‚£è€…ä¿¡æ¯
    patient_info = format_patient_info(
        age, gender, chief_complaint, history_present,
        past_medical, family_history, allergy_history, personal_history
    )

    if not patient_info.strip():
        return [], "âŒ è¯·è‡³å°‘å¡«å†™æ‚£è€…åŸºæœ¬ä¿¡æ¯ã€ä¸»è¯‰æˆ–ç°ç—…å²", []

    # åˆå§‹åŒ–æ¶ˆæ¯å†å²
    messages = [
        {"role": "system", "content": DIAGNOSE_INSTRUCTION},
        {"role": "user", "content": patient_info}
    ]

    # è°ƒç”¨æ¨¡å‹
    try:
        response = diagagent.diagnose(messages)
        messages.append({"role": "assistant", "content": response})

        # æ„å»ºèŠå¤©å†å²æ˜¾ç¤º (ä½¿ç”¨æ–°ç‰ˆ Gradio çš„æ¶ˆæ¯æ ¼å¼)
        chat_history = [
            {"role": "user", "content": "**[æ‚£è€…ä¿¡æ¯]**\n" + patient_info},
            {"role": "assistant", "content": response}
        ]

        return chat_history, f"âœ… è¯Šæ–­å·²å¼€å§‹\n\n{response}", messages

    except Exception as e:
        return [], f"âŒ è¯Šæ–­å¤±è´¥: {str(e)}", []


def continue_diagnosis(exam_result: str, chat_history: List,
                      message_history: List) -> Tuple[List, str, List]:
    """
    ç»§ç»­è¯Šæ–­ - æä¾›æ£€æŸ¥ç»“æœåç»§ç»­

    Args:
        exam_result: æ£€æŸ¥ç»“æœ
        chat_history: Gradio èŠå¤©å†å²
        message_history: æ¨¡å‹æ¶ˆæ¯å†å²

    Returns:
        (updated_chat_history, diagnosis_result, updated_message_history)
    """
    global diagagent

    if not message_history:
        return chat_history, "âŒ è¯·å…ˆå¼€å§‹è¯Šæ–­", message_history

    if not exam_result.strip():
        return chat_history, "âŒ è¯·è¾“å…¥æ£€æŸ¥ç»“æœ", message_history

    # æ·»åŠ ç”¨æˆ·æä¾›çš„æ£€æŸ¥ç»“æœ
    user_message = f"æ£€æŸ¥ç»“æœ:\n{exam_result}"
    message_history.append({"role": "user", "content": user_message})

    # è°ƒç”¨æ¨¡å‹
    try:
        response = diagagent.diagnose(message_history)
        message_history.append({"role": "assistant", "content": response})

        # æ›´æ–°èŠå¤©å†å² (ä½¿ç”¨æ–°ç‰ˆ Gradio çš„æ¶ˆæ¯æ ¼å¼)
        chat_history.append({"role": "user", "content": user_message})
        chat_history.append({"role": "assistant", "content": response})

        return chat_history, f"âœ… è¯Šæ–­å·²æ›´æ–°\n\n{response}", message_history

    except Exception as e:
        return chat_history, f"âŒ è¯Šæ–­å¤±è´¥: {str(e)}", message_history


def reset_session() -> Tuple[List, str, List, str, str, str, str, str, str, str, str]:
    """é‡ç½®ä¼šè¯"""
    return (
        [],  # chat_history
        "",  # diagnosis_result
        [],  # message_history
        "",  # age
        "M",  # gender
        "",  # chief_complaint
        "",  # history_present
        "",  # past_medical
        "",  # family_history
        "",  # allergy_history
        ""   # personal_history
    )


# ============================================================================
# Gradio ç•Œé¢æ„å»º
# ============================================================================
def build_interface():
    """æ„å»º Gradio ç•Œé¢"""

    with gr.Blocks(title="DiagAgent - æ™ºèƒ½è¯Šæ–­åŠ©æ‰‹") as demo:

        # æ ‡é¢˜æ 
        gr.HTML("""
        <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;">
            <h1>ğŸ¤– DiagAgent - RLè®­ç»ƒçš„æ™ºèƒ½è¯Šæ–­åŠ©æ‰‹</h1>
            <p>åŸºäºå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„å¤šè½®äº¤äº’å¼åŒ»ç–—è¯Šæ–­AIç³»ç»Ÿ</p>
        </div>
        """)

        # çŠ¶æ€å˜é‡
        message_history = gr.State([])  # å­˜å‚¨æ¶ˆæ¯å†å²

        with gr.Row():
            # å·¦ä¾§: è¾“å…¥åŒºåŸŸ
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“‹ æ‚£è€…ä¿¡æ¯è¾“å…¥")

                with gr.Group():
                    gr.Markdown("### åŸºæœ¬ä¿¡æ¯")
                    with gr.Row():
                        age_input = gr.Textbox(
                            label="å¹´é¾„",
                            placeholder="ä¾‹å¦‚: 45",
                            scale=1
                        )
                        gender_input = gr.Radio(
                            choices=["M", "F"],
                            label="æ€§åˆ«",
                            value="M",
                            scale=1
                        )

                with gr.Group():
                    gr.Markdown("### ä¸´åºŠä¿¡æ¯")
                    chief_complaint = gr.Textbox(
                        label="ä¸»è¯‰ (Chief Complaint)",
                        placeholder="ä¾‹å¦‚: å³ä¸‹è…¹ç–¼ç—›",
                        lines=2
                    )

                    history_present = gr.Textbox(
                        label="ç°ç—…å² (History of Present Illness)",
                        placeholder="è¯¦ç»†æè¿°æ‚£è€…å½“å‰ç—‡çŠ¶çš„å‘å±•è¿‡ç¨‹...",
                        lines=5
                    )

                    past_medical = gr.Textbox(
                        label="æ—¢å¾€å² (Past Medical History)",
                        placeholder="æ—¢å¾€ç–¾ç—…ã€æ‰‹æœ¯å²ç­‰...",
                        lines=3
                    )

                with gr.Accordion("æ›´å¤šä¿¡æ¯ (å¯é€‰)", open=False):
                    personal_history = gr.Textbox(
                        label="ä¸ªäººå² (Personal History)",
                        placeholder="å¸çƒŸã€é¥®é…’ã€èŒä¸šæš´éœ²ç­‰...",
                        lines=2
                    )

                    family_history = gr.Textbox(
                        label="å®¶æ—å² (Family History)",
                        placeholder="å®¶æ—é—ä¼ ç—…å²...",
                        lines=2
                    )

                    allergy_history = gr.Textbox(
                        label="è¿‡æ•å² (Allergy History)",
                        placeholder="è¯ç‰©è¿‡æ•ã€é£Ÿç‰©è¿‡æ•ç­‰...",
                        lines=2
                    )

                with gr.Row():
                    start_btn = gr.Button("ğŸš€ å¼€å§‹è¯Šæ–­", variant="primary", scale=2)
                    reset_btn = gr.Button("ğŸ”„ é‡ç½®", scale=1)

                gr.Markdown("---")

                # ç»§ç»­è¯Šæ–­åŒºåŸŸ
                gr.Markdown("## ğŸ”¬ ç»§ç»­è¯Šæ–­")
                exam_result_input = gr.Textbox(
                    label="æ£€æŸ¥ç»“æœ",
                    placeholder="è¾“å…¥AIå»ºè®®çš„æ£€æŸ¥é¡¹ç›®çš„ç»“æœ...\nä¾‹å¦‚: è¡€å¸¸è§„: WBC 12.5, RBC 4.2...",
                    lines=4
                )
                continue_btn = gr.Button("â¡ï¸ æäº¤æ£€æŸ¥ç»“æœå¹¶ç»§ç»­", variant="secondary")

            # å³ä¾§: è¾“å‡ºåŒºåŸŸ
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ’¬ è¯Šæ–­è¿‡ç¨‹")

                chat_display = gr.Chatbot(
                    label="å¯¹è¯å†å²",
                    height=400
                )

                diagnosis_output = gr.Markdown(
                    label="å½“å‰è¯Šæ–­ç»“æœ",
                    value="ç­‰å¾…å¼€å§‹è¯Šæ–­..."
                )

                with gr.Accordion("ğŸ“Š ç³»ç»Ÿä¿¡æ¯", open=False):
                    gr.Markdown(f"""
                    <div style="background-color: #f0f4f8; padding: 15px; border-radius: 8px; margin: 10px 0;">
                    <b>æ¨¡å‹ä¿¡æ¯:</b> {MODEL_NAME}<br>
                    <b>å·¥ä½œæ¨¡å¼:</b> å¤šè½®äº¤äº’å¼è¯Šæ–­<br>
                    <b>åŠŸèƒ½:</b>
                    <ul>
                        <li>âœ… æ™ºèƒ½æ¨èæ£€æŸ¥é¡¹ç›®</li>
                        <li>âœ… åŠ¨æ€æ›´æ–°è¯Šæ–­å‡è®¾</li>
                        <li>âœ… è‡ªä¸»å†³å®šè¯Šæ–­æ—¶æœº</li>
                    </ul>
                    <b>æ³¨æ„:</b> é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹(çº¦28GB),è¯·ç¡®ä¿ç½‘ç»œç•…é€šå’Œç£ç›˜ç©ºé—´å……è¶³ã€‚<br>
                    å¦‚æœæ²¡æœ‰GPUæˆ–ä¸æƒ³ä¸‹è½½æ¨¡å‹,ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ã€‚
                    </div>
                    """)

        # æŒ‰é’®äº‹ä»¶ç»‘å®š
        start_btn.click(
            fn=start_diagnosis,
            inputs=[
                age_input, gender_input, chief_complaint,
                history_present, past_medical,
                family_history, allergy_history, personal_history
            ],
            outputs=[chat_display, diagnosis_output, message_history]
        )

        continue_btn.click(
            fn=continue_diagnosis,
            inputs=[exam_result_input, chat_display, message_history],
            outputs=[chat_display, diagnosis_output, message_history]
        ).then(
            fn=lambda: "",  # æ¸…ç©ºæ£€æŸ¥ç»“æœè¾“å…¥æ¡†
            outputs=[exam_result_input]
        )

        reset_btn.click(
            fn=reset_session,
            outputs=[
                chat_display, diagnosis_output, message_history,
                age_input, gender_input, chief_complaint,
                history_present, past_medical, family_history,
                allergy_history, personal_history
            ]
        )

        # ç¤ºä¾‹
        gr.Examples(
            examples=[
                [
                    "65", "F", "è…¹ç—›ã€ä½“é‡ä¸‹é™",
                    "æ‚£è€…æŠ¥å‘Š1ä¸ªæœˆæ¥ä½“é‡ä¸‹é™10ç£…,æ—©é¥±æ„Ÿ,ç–²åŠ³å’Œç¼ºä¹ç²¾åŠ›ã€‚å¥¹æè¿°èƒƒéƒ¨æœ‰ä¸€ç§\"ç©º\"çš„æ„Ÿè§‰,ä¸æ¶å¿ƒæˆ–ç–¼ç—›ä¸åŒã€‚",
                    "å“®å–˜ã€é«˜è„‚è¡€ç—‡ã€é«˜è¡€å‹ã€éª¨å…³èŠ‚ç‚ã€é£æ¹¿æ€§å¤šè‚Œç—›ã€å† å¿ƒç—…(NSTEMIä¼´LADå¤¹å±‚)ã€éª¨è´¨ç–æ¾ç—‡",
                    "çˆ¶äº²æœ‰å† å¿ƒç—…;æ¯äº²æœ‰å“®å–˜ã€‚æ— æ—©æœŸå¿ƒè‚Œæ¢—æ­»ã€å¿ƒå¾‹å¤±å¸¸ã€å¿ƒè‚Œç—…æˆ–å¿ƒæºæ€§çŒæ­»å®¶æ—å²ã€‚",
                    "èµ–è¯ºæ™®åˆ©",
                    "æœªæä¾›"
                ],
                [
                    "28", "F", "å³ä¸‹è…¹ç–¼ç—›",
                    "æ‚£è€…G3P2,æœ«æ¬¡æœˆç»___,æœ‰å­å®«å†…è†œå¼‚ä½ç—‡ç—…å²,å› å³ä¸‹è…¹ç–¼ç—›åˆ°æ€¥è¯Šå°±è¯Šã€‚æ‚£è€…æŠ¥å‘Šç–¼ç—›å§‹äºæ˜¨å¤©ä¸‹åˆæ™šäº›æ—¶å€™,æœ€åˆä¸ºå³ä¸‹è…¹éšç—›,åè½¬ä¸ºé”ç—›,æœªå¤ªå›°æ‰°å¥¹,èƒ½ç»§ç»­æ´»åŠ¨,åè‡ªè¡Œç¼“è§£ã€‚ä»Šæ™¨ç–¼ç—›å¤å‘,é¢‘ç‡å’Œå¼ºåº¦è¾ƒæ˜¨å¤©å¢åŠ ,é”ç—›/åˆºç—›,é—´æ­‡æ€§,æŒç»­5-20åˆ†é’Ÿã€‚",
                    "æŠ‘éƒã€ç„¦è™‘;å­å®«å†…è†œå¼‚ä½ç—‡è…¹è…”é•œæ‰‹æœ¯x2",
                    "æ— æ˜æ˜¾å¼‚å¸¸",
                    "é’éœ‰ç´ ã€é˜¿è«è¥¿æ—ã€ä¹³èƒ¶",
                    "è¿‡å»___å¹´æœªæœ‰æ€§ç”Ÿæ´»"
                ]
            ],
            inputs=[
                age_input, gender_input, chief_complaint,
                history_present, past_medical, family_history,
                allergy_history, personal_history
            ],
            label="ğŸ“ ç¤ºä¾‹ç—…ä¾‹ (ç‚¹å‡»åŠ è½½)"
        )

        # é¡µè„šä¿¡æ¯
        gr.Markdown("""
        ---
        ### ğŸ“š ä½¿ç”¨è¯´æ˜
        1. **å¡«å†™æ‚£è€…ä¿¡æ¯**: è‡³å°‘å¡«å†™åŸºæœ¬ä¿¡æ¯ã€ä¸»è¯‰å’Œç°ç—…å²
        2. **å¼€å§‹è¯Šæ–­**: ç‚¹å‡»"å¼€å§‹è¯Šæ–­"æŒ‰é’®,AIä¼šåˆ†æå¹¶ç»™å‡ºåˆæ­¥è¯Šæ–­æˆ–å»ºè®®æ£€æŸ¥
        3. **æä¾›æ£€æŸ¥ç»“æœ**: å¦‚æœAIå»ºè®®åšæ£€æŸ¥,åœ¨"æ£€æŸ¥ç»“æœ"æ¡†è¾“å…¥ç»“æœå¹¶ç‚¹å‡»"æäº¤"
        4. **é‡å¤æ­¥éª¤3**: ç›´åˆ°AIç»™å‡ºæœ€ç»ˆè¯Šæ–­

        ### âš ï¸ å…è´£å£°æ˜
        æœ¬ç³»ç»Ÿä»…ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„,ä¸åº”æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€è¯Šæ–­æˆ–æ²»ç–—ã€‚ä»»ä½•åŒ»ç–—å†³ç­–éƒ½åº”å’¨è¯¢åˆæ ¼çš„åŒ»ç–—ä¸“ä¸šäººå‘˜ã€‚

        ### ğŸ“– å‚è€ƒèµ„æ–™
        - è®ºæ–‡: [Evolving Diagnostic Agents in a Virtual Clinical Environment](http://arxiv.org/abs/2510.24654)
        - æ¨¡å‹: [HuggingFace - DiagAgent](https://huggingface.co/Henrychur/DiagAgent-14B)
        - GitHub: [DiagGym](https://github.com/...)
        """)

    return demo


# ============================================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================================
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="DiagAgent Gradio Web Interface")
    parser.add_argument(
        "--model",
        type=str,
        default="/input0/DiagAgent-14B",
        help="æ¨¡å‹åç§°æˆ–è·¯å¾„ (é»˜è®¤: Henrychur/DiagAgent-14B)"
    )
    parser.add_argument(
        "--mock",
        action="store_true",
        help="ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼(ä¸åŠ è½½çœŸå®æ¨¡å‹)"
    )
    parser.add_argument(
        "--share",
        action="store_true",
        help="åˆ›å»ºå…¬å¼€åˆ†äº«é“¾æ¥"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8080,
        help="æœåŠ¡ç«¯å£ (é»˜è®¤: 8080)"
    )
    parser.add_argument(
        "--server-name",
        type=str,
        default="0.0.0.0",
        help="æœåŠ¡å™¨åœ°å€ (é»˜è®¤: 0.0.0.0)"
    )

    args = parser.parse_args()

    # æ›´æ–°å…¨å±€æ¨¡å‹åç§°
    MODEL_NAME = args.model

    # é¢„åˆå§‹åŒ–æ¨¡å‹
    print("="*60)
    print("DiagAgent Gradio Web Interface")
    print("="*60)

    if args.mock:
        print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ (æœªåŠ è½½çœŸå®æ¨¡å‹)")
        diagagent = TransformersLocalDiagAgent(MODEL_NAME)
        diagagent.model = None
    else:
        print(f"æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: {MODEL_NAME}")
        print("é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹,è¯·è€å¿ƒç­‰å¾…...")
        diagagent = TransformersLocalDiagAgent(MODEL_NAME)

    print("="*60)

    # æ„å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = build_interface()

    demo.launch(
        share=args.share,
        server_name=args.server_name,
        server_port=args.port,
        show_error=True
    )
